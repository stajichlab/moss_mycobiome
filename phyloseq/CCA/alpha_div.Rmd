---
title: "Mojave_Colorado_Div_ITS_phyloseq"
author: "Kian Kelly and Nuttapon Pombupba"
date: "Updated on December 21, 2023"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###STEP1: Load all necessary packages

```{r warning=FALSE, message=FALSE}
library(ape)
library(vegan)
library(dplyr)
library(scales)
library(grid)
library(reshape2)
library(phyloseq)
library(magrittr)
library(ggplot2)
library(ggpubr)
library(plyr)
library(data.table)
library(tidyr)
library(tidyverse)
library(multcompView)
library(MoMAColors)

```

####Initiallize functions
This function was written by Joey (but it is not part of phyloseq
package) <https://github.com/joey711/phyloseq/issues/418>

Kian notes: This defines functions which will be used in future steps. fast_melt takes an input which is a physeq object, extracts OTU table, modifies this (ie removes NA values). summarize_taxa summarizes the relative abundance data by taxonomic rank, but can also be used with grouping variables (ie crust type) and can calculate summary stats. The result is a data.table containing mean, standard deviation, minimum, and maximum relative abundances for each taxonomic group.

```{r warning=FALSE}
fast_melt = function(physeq){
  # supports "naked" otu_table as `physeq` input.
  otutab = as(otu_table(physeq), "matrix")
  if(!taxa_are_rows(physeq)){otutab <- t(otutab)}
  otudt = data.table(otutab, keep.rownames = TRUE)
  setnames(otudt, "rn", "taxaID")
  # Enforce character taxaID key
  otudt[, taxaIDchar := as.character(taxaID)]
  otudt[, taxaID := NULL]
  setnames(otudt, "taxaIDchar", "taxaID")
  # Melt count table
  mdt = melt.data.table(otudt, 
                        id.vars = "taxaID",
                        variable.name = "SampleID",
                        value.name = "count")
  # Remove zeroes, NAs
  mdt <- mdt[count > 0][!is.na(count)]
  # Calculate relative abundance
  mdt[, RelativeAbundance := count / sum(count), by = SampleID]
  if(!is.null(tax_table(physeq, errorIfNULL = FALSE))){
    # If there is a tax_table, join with it. Otherwise, skip this join.
    taxdt = data.table(as(tax_table(physeq, errorIfNULL = TRUE), "matrix"), keep.rownames = TRUE)
    setnames(taxdt, "rn", "taxaID")
    # Enforce character taxaID key
    taxdt[, taxaIDchar := as.character(taxaID)]
    taxdt[, taxaID := NULL]
    setnames(taxdt, "taxaIDchar", "taxaID")
    # Join with tax table
    setkey(taxdt, "taxaID")
    setkey(mdt, "taxaID")
    mdt <- taxdt[mdt]
  }
  return(mdt)
}

summarize_taxa = function(physeq, Rank, GroupBy = NULL){
  Rank <- Rank[1]
  if(!Rank %in% rank_names(physeq)){
    message("The argument to `Rank` was:\n", Rank,
            "\nBut it was not found among taxonomic ranks:\n",
            paste0(rank_names(physeq), collapse = ", "), "\n",
            "Please check the list shown above and try again.")
  }
  if(!is.null(GroupBy)){
    GroupBy <- GroupBy[1]
    if(!GroupBy %in% sample_variables(physeq)){
      message("The argument to `GroupBy` was:\n", GroupBy,
              "\nBut it was not found among sample variables:\n",
              paste0(sample_variables(physeq), collapse = ", "), "\n",
              "Please check the list shown above and try again.")
    }
  }
  # Start with fast melt
  mdt = fast_melt(physeq)
  if(!is.null(GroupBy)){
    # Add the variable indicated in `GroupBy`, if provided.
    sdt = data.table(SampleID = sample_names(physeq),
                     var1 = get_variable(physeq, GroupBy))
    setnames(sdt, "var1", GroupBy)
    # Join
    setkey(sdt, SampleID)
    setkey(mdt, SampleID)
    mdt <- sdt[mdt]
  }
  # Summarize
  Nsamples = nsamples(physeq)
  summarydt = mdt[, list(meanRA = sum(RelativeAbundance)/Nsamples,
                         sdRA = sd(RelativeAbundance),
                         minRA = min(RelativeAbundance),
                         maxRA = max(RelativeAbundance)),
                  by = c(Rank, GroupBy)]
  return(summarydt)
}

plot_taxa_summary = function(physeq, Rank, GroupBy = NULL){
  # Get taxa summary table 
  dt1 = summarize_taxa(physeq, Rank = Rank, GroupBy = GroupBy)
  # Set factor appropriately for plotting
  RankCol = which(colnames(dt1) == Rank)
  setorder(dt1, -meanRA)
  dt1[, RankFac := factor(dt1[[Rank]], 
                          levels = rev(dt1[[Rank]]))]
  dt1[, ebarMax := max(c(0, min(meanRA + sdRA))), by = eval(Rank)]
  dt1[, ebarMin := max(c(0, min(meanRA - sdRA))), by = eval(Rank)]
  # Set zeroes to one-tenth the smallest value
  ebarMinFloor = dt1[(ebarMin > 0), min(ebarMin)]
  ebarMinFloor <- ebarMinFloor / 10
  dt1[(ebarMin == 0), ebarMin := ebarMinFloor]
  
  pRank = ggplot(dt1, aes(x = meanRA, y = RankFac)) +
    scale_x_log10() +
    xlab("Mean Relative Abundance") +
    ylab(Rank) +
    theme_bw()
  if(!is.null(GroupBy)){
    # pRank <- pRank + facet_wrap(facets = as.formula(paste("~", GroupBy)))
    pRank <- pRank + geom_point(mapping = aes_string(colour = GroupBy),
                                size = 5)
  } else {
    # Don't include error bars for faceted version
    pRank <- pRank + geom_errorbarh(aes(xmax = ebarMax,
                                        xmin = ebarMin))
  }
  return(pRank)
}
```

###STEP2: Import Mapping file (metadate file) 

Kian notes:

I excluded Nat's samples from this analysis by removing them from the metadata file. 

```{r}
meta = read.table("metadata.tsv",header=TRUE,row.names=1,sep="\t",stringsAsFactors=FALSE)
```

###STEP3: Check if your metadata file has been imported successfully 

```{r warning=FALSE}
head(meta)
```

###STEP4: Construct sample_data-class using imported metadata

Kian notes: basically makes a phyloseq version of your metadata file
```{r}
sampleData <- sample_data(meta)
```

###STEP5: Import OTU table
Kian notes: OTU table here combines my data with Nat's.
NOTE: IF THE HEADER IS IMPROPERLY READ, REMOVE THE COMMA ADDED BY PHYLOSEQ!!!
```{r}
getwd()
otus <- read.table("Mojave2020_KKelly202307.otu_table.txt",header=T,sep="\t",row.names=1)
otumat <- as(as.matrix(otus), "matrix")
OTU = otu_table(otumat, taxa_are_rows = TRUE)
```

Check imported OTU table

```{r warning=FALSE}
head(OTU)
```

###STEP6: Import taxonomy table Taxonmy 
Note: table generated from AMPtk needs to be rearranged using a perl script.

"perl rdp_taxonmy2mat.pl\<Input_taxonmy.txt\>Output_taxonomy.txt"

rdp_taxonomy2mat.pl was created by Professor Jason E. Stajich

```{r}
taxmat <- read.table("Mojave2020_KKelly202307.ASVs.taxonomy.fix.txt", header=T,sep="\t",row.names=1)
taxmat <- as(as.matrix(taxmat),"matrix")
TAX = tax_table(taxmat)
head(TAX)
```

###STEP7: Import phylogenetic tree

```{r warning=FALSE}
#treefile = "Mojave2020_KKelly202307.ASVs.tree.phy"
#tree = read.tree(treefile)
```

###STEP8: Construct Phyloseq object 

To construct phyloseq object, otu
table, taxonomy table, and sampleData are required. Phylogenetic tree
can be included, but it is not necessary for constructing phyloseq
object. Construct Phyloseq object called "Physeq"

```{r warning=FALSE}
sample_names(OTU)
sample_names(TAX)
sample_names(sampleData)


physeq = phyloseq(OTU,TAX,sampleData)
```

Check phyloseq object This should indicate that your physeq is a
"phyloseq-class experiment-level object""

```{r warning=FALSE}
physeq
```

###STEP9: Remove singletons Remove any OTUs that present only one time.

```{r }
physeq.prune = prune_taxa(taxa_sums(physeq) > 1, physeq)
```

```{r warning=FALSE}
physeq.prune
```

###STEP10: Plot read counts to check dataset 
Check read counts: any samples that have very low reads should be removed.
[Ref](http://evomics.org/wp-content/uploads/2016/01/phyloseq-Lab-01-Answers.html)

```{r}
readcount = data.table(as(sample_data(physeq.prune), "data.frame"),
                 TotalReads = sample_sums(physeq.prune), 
                 keep.rownames = TRUE)
setnames(readcount, "rn", "SampleID")

```

TotalReads of all the samples can be in this table (select only SampleID
and TotalReads columns). In order to check samples with low number of
reads, "order()" can be used to sort "TotalReads" column. In this
dataset, N55.Rhizo has very low number of reads, so will will filter
this sample out using the next minimum number of reads.

```{r}
readcount = readcount[order(readcount$TotalReads), c("SampleID", "TotalReads")]
```

```{r}
head(readcount)
```



###STEP11: Rarefaction curve 
Extract OTU table, transpose and convert to Extract OTU table from phyloseq object as data frame and use vegan to calculate rarefaction curve

```{r}
otu.rare <- otu_table(physeq.prune.rarefy)
otu.rare <- as.data.frame(t(otu.rare))
sample_names <- rownames(otu.rare)

#vegan rarecurve 
otu.rarecurve <- rarecurve(otu.rare, step = 500, sample = 30000, label = T)
```
this code takes a list of rarefaction curves (otu.rarecurve), converts each curve into a data frame, creates a new data frame with columns "OTU" and "Sample.size," adjusts the format of the "Sample.size" column, and returns a list of modified data frames (rare). The goal is to organize and preprocess the data for furthervisualization.

```{r}
rare <- lapply(otu.rarecurve, function(x){
  b <- as.data.frame(x)
  b <- data.frame(OTU = b[,1], Sample.size = rownames(b))
  b$Sample.size <- as.numeric(gsub("N", "",  b$Sample.size))
  return(b)
})
```

label list

```{r}
names(rare) <- sample_names
```

convert to data frame

```{r}
#tidyverse
rare <- map_dfr(rare, function(x){
  z <- data.frame(x)
  return(z)
}, .id = "sample")
```

```{r}
head(rare)
```


###STEP11.1: Plot Fungal Alpha diversity by Substrate (Chao1 and Observed)

Alpha diversity can be
Chao1, Observed, Shannon, Simpson This plot include statistical analysis
using "stat_compare_means" with "method = anova"


```{r}
ps <- transform_sample_counts(physeq.prune, function(x) x / sum(x))

# Add a fake dummy variable Depth so that there are two with interaction,
# like in example
#sample_data(physeq.prune)$Depth <- sample(150:500, nsamples(physeq), replace = TRUE)
cca_litdir = ordinate(ps ~ Climate + Site, "CCA")
# Mimic biplot from example
p0 = plot_ordination(ps, cca_litdir, type = "samples", color = "Climate", shape = "Site")
p0
```

```{r}
# Now add the environmental variables as arrows
arrowmat = vegan::scores(cca_litdir, display = "bp")
# Add labels, make a data.frame
arrowdf <- data.frame(labels = rownames(arrowmat), arrowmat)
# Define the arrow aesthetic mapping
arrow_map = aes(xend = CCA1, yend = CCA2, x = 0, y = 0, shape = NULL, color = NULL, 
    label = labels)https://vscode-remote+tunnel-002br11.vscode-resource.vscode-cdn.net/scratch/kkell060/8984230/RtmpASc5hJ/vscode-R/plot.png?version%3D1732644659560
label_map = aes(x = 1.2 * CCA1, y = 1.2 * CCA2, shape = NULL, color = NULL, 
    label = labels)
# Make a new graphic
arrowhead = arrow(length = unit(0.05, "npc"))
p1 = p0 + geom_segment(arrow_map, size = 0.5, data = arrowdf, color = "gray", 
    arrow = arrowhead) + geom_text(label_map, size = 2, data = arrowdf)
p1
```